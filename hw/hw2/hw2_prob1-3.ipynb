{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2\n",
        "\n",
        "## Problem 1:\n",
        "\n",
        "### a. solution:\n",
        "\\begin{bmatrix} \n",
        "\t0.1 & 0.1 & 0.1 \\\\\n",
        "\t0.1 & 0.1 & 0.1\\\\\n",
        "\t0.1 & 0.1 & 0.1 \\\\\n",
        "\t\\end{bmatrix}\n",
        "\n",
        "### b. solution:\n",
        "\\begin{bmatrix} \n",
        "\t-1 & -2 & -1 \\\\\n",
        "\t0 & 0 & 0\\\\\n",
        "\t1 & 2 & 1 \\\\\n",
        "\t\\end{bmatrix}\n",
        "\n",
        "### c. solution:\n",
        "\\begin{bmatrix} \n",
        "\t-1 & 0 & 1 \\\\\n",
        "\t-2 & 0 & 2\\\\\n",
        "\t-1 & 0 & 1 \\\\\n",
        "\t\\end{bmatrix}\n",
        "\n",
        "### d. solution:\n",
        "\\begin{bmatrix} \n",
        "\t-1 & -1 & 0 \\\\\n",
        "\t-1 & 0 & 1\\\\\n",
        "\t0 & 1 & 1 \\\\\n",
        "\t\\end{bmatrix}"
      ],
      "metadata": {
        "id": "owS5u517feER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "### a. solution:\n",
        "\n",
        "$L_{original}(w)=∑_{i=0}^{n}(y_{i}-∑_{d=0}^{m}x_{ij}w_{j})^{2}$\n",
        "\n",
        "$L_{new}(w)=L_{original}(w)+λw^{T}w$\n",
        "\n",
        "### b. solution:\n",
        "\n",
        "$∇_{w}L_{new}(w)=2λw+∇_{w}L_{original}(w)$\n",
        "\n",
        "\n",
        "### c. solution:\n",
        "\n",
        "$w_{new}=w_{original}-ϵ(2λw_{original}+∇_{w}L_{original}(w_{original}))$\n",
        "\n",
        "$w_{new}=(1-2λϵ)w_{original}-ϵ∇_{w}L_{original}(w_{original})$\n",
        "\n",
        "Conlusively, the value of w would decrease in each update.\n",
        "\n",
        "### d. solution:\n",
        "\n",
        "The learning rate will interact with many other aspects of the optimization process, and the interactions may be nonlinear. Nevertheless, in general, smaller learning rates will require more training epochs. Conversely, larger learning rates will require fewer training epochs. Further, smaller batch sizes are better suited to smaller learning rates given the noisy estimate of the error gradient.\n",
        "\n",
        "Bascially, we cannot analytically calculate the optimal learning rate for a given model on a given dataset. A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point."
      ],
      "metadata": {
        "id": "tcUH1_1JzWxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3\n",
        "### a. solution:\n",
        "$IoU= \\frac{Area of Overlapping}{Area of Union}$\n",
        "\n",
        "Area of Overlapping and Area of Union is positive number and Area of Overlapping is no larger than Area of Union. So IoU value is always a non- negative real number bewtween 0 and 1.\n",
        "\n",
        "### b. solution:\n",
        "Assuming that box1 with the top-left and bottom-right coordinates [x1,y1,x2,y2] and box2 with the top-left and bottom-right coordinates [x1,y1,x2,y2]\n",
        "\n",
        "xi1 = max(box1[0],box2[0])\n",
        "\n",
        "yi1 = max(box1[1],box2[1])\n",
        "\n",
        "xi2 = min(box1[2],box2[2])\n",
        "\n",
        "yi2 = min(box1[3],box2[3])\n",
        "\n",
        "inter_area = (yi2-yi1)*(xi2-xi1)\n",
        "  \n",
        "\n",
        "box1_area = (box1[2]-box1[0])*(box1[3]-box1[1])\n",
        "\n",
        "box2_area = (box2[2]-box2[0])*(box2[3]-box2[1])\n",
        "\n",
        "union_area = box1_area+box2_area-inter_area\n",
        "\n",
        "    \n",
        "\n",
        "IoU = inter_area/union_area\n",
        "\n",
        "$\\frac{∂IoU}{∂x_{1}}$,\n",
        "$\\frac{∂IoU}{∂x_{2}}$,\n",
        "$\\frac{∂IoU}{∂y_{1}}$,\n",
        "$\\frac{∂IoU}{∂y_{2}}$ those gradients is meaningless and cannot be used as a loss function\n",
        "\n"
      ],
      "metadata": {
        "id": "5pR2rrhQOItX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVM9AWXLfcCD"
      },
      "outputs": [],
      "source": []
    }
  ]
}